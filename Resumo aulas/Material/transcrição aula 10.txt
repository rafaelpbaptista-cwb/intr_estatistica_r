CDA Turma 4: aula 10, Estatística Básica e Introdução ao R - Profa. Natália Giordani - YouTube
https://www.youtube.com/watch?v=DNyoweKUPkI

Transcript:
(00:01) foi boa noite pessoal está sendo gravada chegamos a nossa última aula E aí qual é a ideia pra aula de hoje a gente vai dividir H basicamente a nossa aula em duas partes na primeira parte a gente vai falar um pouquinho sobre o modelo que a gente ainda não viu que é o modelo de regressão logística Ah vamos fazer um exemplo passando pelos principais pontos que a gente precisa ter cuidado sempre que a gente tá olhando para essa classe de modelos e hã depois a gente vai tentar vamos fazer um exemplo e vamos tentar discutir um pouquinho sobre fazer
(00:38) o encerramento da disciplina ã Essa é que vai ser a nossa o nosso caminho o que a gente vai conversar e discutir um pouquinho na aula de hoje então só vou começar falando sobre uma dúvida que que surgiu antes da gravação ser iniciada como é que a gente faz para ver o conjunto os conjuntos né os dados que estão disponíveis no software R tá lá na primeira linha da sintaxe da aula 9ve da aula passada Esse comando tá nos mostrando todos os nomes dos conjuntos de dados que tem seguido de uma breve descrição deles e aí a gente utiliza
(01:18) eles da mesma forma que a gente utilizou os outros dados na que a gente usou aqui na disciplina e hoje também a gente vai fazer um exemplo com dados que são do próprio R usa a mesma a mesma maneira não é diferente ã sobre o moodle então eu coloquei lá no Moodle eh já os slides que a gente vai falar para na aula de hoje também coloquei a sintaxe que a gente vai utilizar hoje hã encerra o período da da entrega do trabalho que vocês fizeram em dupla sobre teste de hipóteses e eu já deixei lá duas caixinhas uma para entrega do exercício três e uma
(02:05) para entrega do exercício de recuperação então lembrando Qual que é a ideia de cada um desses trabalhos vocês vão escolher um conjunto de dados que seja do interesse de vocês vão aplicar ou regressão linear múltipla ou regressão logística e o que vocês vão entregar vai ser um relatório né um arquivo HTML em formato de relatório que tem que contemplar ou ter Vocês precisam especificar o objetivo da análise de escrever um parágrafo contextualizando os dados que vocês vão utilizar fazer o ajuste do modelo e a avaliação do ajuste
(02:42) um parágrafo descrevendo o Que Vocês Fizeram ali nas etapas de ajuste e avaliação e interpretar os resultados dado o objetivo da análise de vocês Então essa é a entrega do trabalho três exercício de recuperação para quem não atingir a média da disciplina eu vou corrigir também o exercício de recuperação só nesses casos senão não vou olhar para esse para esse para esse exercício a ideia do exercício de Recuperação é exatamente a mesma ideia do que o trabalho três ã Mas vocês vão fazer a outra técnica Então se no exercício três
(03:21) vocês entregaram regressão logística no de recuperação vocês vão olhar para regressão linear múltipla ou contrário Certo Sobre isso eh é sete a média das disciplinas suan certo então vamos começar com regressão logística então regressão logística ela é uma técnica análogo à regressão linear múltipla Mas ela é aplicada num contexto em que a gente tá olhando para uma variável resposta n a nossa variável Y do tipo binária né é uma resposta dicotômica aqui nós vamos tratar de uma
(04:24) resposta dicotômica então ã numa situação em que a gente tem só duas possíveis respostas um sim ou não uma falha ou um sucesso uma característica de adimplência ou inadimplência E qual vai ser o nosso objetivo aqui vai ser modelar a resposta esperada que a gente via lá na regressão linear múltipla que é escrita em termos de esperança de y dado x mas aqui a resposta que a gente modela é um tem um formato de uma probabilidade e isso é função das covariáveis né das variáveis explicativas os X que a gente tá interessados a gente vai olhar para
(05:11) esse formato em seguida exemplos que a gente pode aplicar regressão logística quando a gente tá falando eh num quando a gente tem o interesse de avaliar fatores de risco que a gente comumente se refere Quais são os fatores por exemplo associ ao cancelamento de um plano ou a desenvolvimento de uma doença qual é a probabilidade de ch de um cliente ou de um colaborador qual é a probabilidade de um cliente ser inadimplente algum outro exemplo Alguém tem em todas essas situações são casos em que a nossa variável resposta ela é
(05:58) do tipo zero ou um sim ou não então olhando de uma forma um pouco mais teórica o que a gente tá modelando na na regressão logística é um logito é o logito de p quem é p é a probabilidade de y ser igual a 1 dado as minhas covariáveis e é por conta desta transformação que a gente usa é a transformação logística né O logit que o é descrito como regressão logística Então por debaixo dos panos o que a gente faz é modelar o logaritmo da Razão de duas probabilidades a probabilidade de y ser igual a 1 dividido pela probabilidade de y ser
(06:47) igual a zer né o complemento da probabilidade de y ser igual a 1 esta razão aqui a razão de duas probabilidades ela é chamada de chance Então o que a gente tá fazendo aqui é modelando o logaritmo da chance como função das nossas covariáveis explicativas dos X que a gente tem interesse em modelar E por que que a gente faz isso né Por que que simplesmente a gente não modela igual a gente faz lá na regressão linear múltipla uma esperança de y porque se a gente modelar a esperança de Y como a gente faz lá usando mesmo
(07:33) raciocínio a gente teria valores de de de y que tão definidos estariam definidos num intervalo que vai de menos infinito a mais infinito e a ideia é deixar isso no intervalo zer ou um para conseguir fazer esse ajuste né para conseguir controlar os limites é feita essa manipulação esse ajuste técnico Ahã Então a partir desse dessa equação aqui da primeira linha a gente consegue por algumas manipulações matemáticas chegar no valor da probabilidade de y ser igual a 1 como uma função ali também das nossas covariáveis né dos betas estimados ali
(08:23) pelo modelo de regressão linear eh logística eh lá no modelo de regressão Lar múltipla os parâmetros do nosso modelo eles eram obtidos através do método de mínimos quadrados lembram aqui a gente tá num contexto diferente e os nossos parâmetros também são obtidos de uma maneira diferente aqui a gente tá utilizando o método da máxima veros semelhança que que esse método faz ele vai fornecer valores pros parâmetros desconhecidos né pros nossos betas que vão maximizar a probabil idade da gente obter os dados observados na nossa
(09:03) amostra com base naqueles parâmetros ou seja são as estimativas que melhor representam os dados observados na minha amostra Essa é a ideia do método da máxima veros semelhança de uma maneira fácil que que a gente interpreta aqui quando a gente tava lá no contexto de regressão linear múltipla o que a gente interpretava era diretamente os nossos betas Nesse contexto o que a gente interpreta é a exponencial dos betas que é o que a gente chama de razão de chances ou ods ratio quando o exponencial desse Beta for maior que um a gente diz que tem uma
(09:45) fator de risco ou seja ele tá aumentando a chance do evento que a gente tá modelando acontecer se o ods ratio for menor do que um a gente se refere a ele como um fator de proteção reduz a chance do evento acontecer e quando ele for igual a um significa que ele não afeta não tá relacionado à chance do evento acontecer modelo ajustado Quais são os pontos que são importantes da gente avaliar aqui a gente também tem algumas alterações algumas especificidades em relação ao modelo anterior a gente olha primeiro botei elenquei aqui três
(10:28) tópicos para falar falar sobre quatro itens né primeiro uma estatística de medida Geral do ajuste do modelo que é a estatística de teste é o teste de rosmy lemesou qual que é a ideia aqui do teste de rosem lemesou para cada Y para cada variável observada a gente estima a probabilidade de y ser igual a 1 os dados são Então ordenados por essa probabilidade de maneira crescente são divididos em 10 grupos para ter uma uma representação dos percentis E aí em cada um dos grupos a gente sabe quantos uns qual é qual o número de observações um
(11:09) que a gente tem e qual é o número de observações um estimadas Pelo modelo a comparação entre a a Eh esses números né o observado e o esperado Segue uma distribuição que quadrado e o que a gente vai testar então a hipótese nula desse modelo é que o modelo tem um B ajuste aos dados essa aqui é uma situação em que o nosso interesse é não rejeitar a hipótese nula a gente quer concluir que o nosso modelo ele se ajusta bem aos dados que a gente tá modelando ã avaliação das medidas de influência então lembrando da aula passada a gente
(11:53) usa também aqui a distância de cook da mesma forma como a gente tinha feito lá na aula passada e e o que que fazem essas medidas de influência né Elas alteram o valor dos coeficientes dos betas avaliação dos resíduos aqui nessa situação a gente tem eh dois tipos de resíduos ã que são calculados né a gente já não a gente não tá olhando para um contexto de valor esperado de y a gente tá num contexto de duas probabilidades então existem formas de distintas de calcular os resíduos sendo que as duas mais utilizadas e mais
(12:34) conhecidas são os resíduos de pearson e os resíduos de deviance os resíduos de pearson eles nada mais são do que a diferença entre o valor observado e o valor predito Pelo modelo dividido pelo desvio padrão dos valores preditos Em contrapartida os resíduos deviam-se eles se baseiam lá naquela função de veros semelhança do modelo E aí eles estão eles é uma medida uma estatística que utiliza o log da veros semelhança para computar ã os resíduos então daqui o importante é saber a gente tá num contexto em que os resíduos são
(13:15) calculados de uma maneira diferente e existem dois tipos que nos ajudam nessa situação resíduos de pearson resíduos de deviance que que a gente vai olhar aqui se a gente tem algum padrão a mesma ideia que a gente usar Ava lá pro modelo de regressão linear múltipla mas adaptada ao contexto do modelo de regressão logística agora a gente vai olhar um pouco para essas questões que a gente falou aqui ã num conjunto de dados que a gente que é lá do R que a gente até já olhou para ele em alguma das outras aulas que é um
(13:51) conjunto de baixo eh baixo peso ao nascer E qual vai ser o nosso objetivo a gente vai est olhando para fatores de risco para baixo peso da criança que que a gente vai desenvolver e discutir aqui ajuste do modelo avaliação do ajuste e interpretação dos coeficientes a gente vai tá olhando pro ajuste do modelo de acordo com ã o proposto por dois autores que são referência quando a gente fala em regressão logística inclusive são os autores da aquele teste de qualidade de de ajuste do modelo que é o rosm elem show ã eles têm um esse livro deles de
(14:36) regressão logística aplicada discute ã um contexto com exatamente essas esses dados então recomendo para quem quer se aprofundar um pouco mais sobre isso o livro deles sobre esse assunto e eh Por que que a gente coloquei aqui que a gente vai eh tem como objetivo identificar fatores de risco para baixo peso da criança porque a gente também pode usar o modelo de regressão logística com o enfoque de estimar uma probabilidade classificar as crianças né Novas crianças como qual é a probabilidade dela ter baixo peso a
(15:11) nascer sim ou não então olhar para esse modelo como um modelo de classificação Por que que a gente não vai olhar para esse enfoque porque vocês vão ver isso nas próximas disciplinas quando sempre que vocês falarem de modelos de classificação um deles é regressão logística o mais simples dele e aí existem H formas complementares da gente avaliar a capacidade preditiva do modelo que inclui por exemplo aquela eh eh lá quando a gente tava falando de tabelas e contingência teve uma aula que a gente falou sobre especificidade sensibilidade sobre
(15:47) acurácia então envolvem aqueles conceitos como vocês vão tratar daqui a pouco né nas próximas disciplinas esse tema eu decidi focar aqui na exploração dos fatores de risco a avaliação do ajuste e interpretação sob esse so essa perspectiva certo pessoal então vamos lá a sintaxe também já tá lá no lá no Moodle Deixa eu só me organizar Aqui esse tamanho ai Vocês conseguem ver bem sim ótimo todo mundo já tá com com o código em mous Então vamos começar ã coloquei aqui um resuminho da ideia a
(16:52) gente vai olhar especificamente para três com variáveis a gente vai trabalhar com dados de baixo peso a nascer e a gente vai vai assumir que faz sentido pra gente avaliar três características a idade da mãe o peso e eh uma variável indicadora que tem valor um se a mãe fumou na gestação e zero se ela não fumou eh e aí eu coloquei que a gente tá pensando num contexto em que o nosso interesse vai ser olhar e entender os fatores de riscos de risco associados ao baixo peso da criança ao nascer ah acredito que o único pacote que vocês
(17:34) não tenham instalado é esse glm toolbox e se quiserem já fazer a instalação enquanto a gente vai discutindo os outros itens para na hora que a gente for usar ele mais para baixo Quando a gente tiver falando lá sobre o diagnóstico de ajuste de modelo vocês já terem lembrando É só colocar usar o comando instal P packages botar uma asinha e colocar o nome do pacote ou vir aqui e clicar Eh escrever o pacote fazer a instalação ali clicando Então vou começar carregando os pacotes que a gente vai utilizar E aí aí Relembrando escolhi o dataset que eu
(18:17) quero trabalhar eu vou fazer já uma analogia com o que a gente falou no início da aula escolhi o dataset lá que eu quero se eu colocar ponto de interrogação e o nome dele que que a gente vai ter a vai abrir aqui no help oh meu Deus e ele tá me gravou é ele tá fazendo pegadinha comigo mas tá aqui ó ele abre aqui no help uma descrição desse conjunto de dados então aqui tá nos dizendo são 189 linhas e 10 colunas de dados que foram coletados num centro médico no ano de 1986 E aí ele vai nos indicar o que que representa cada uma das colunas que ele
(19:06) apresenta é é um dicionário dos dados então no nosso contexto específico o que que eu fiz eu tô colocando nesse objeto dados apenas as colunas que são do nosso interesse Então a primeira variável ela indica se teve se a criança teve baixo peso Quando nasceu e aqui ele classifica como baixo peso todas as crianças que tiveram menos e 2,5 kg quando nasceram isso eu sei ã porque tá descrito aqui no dicionário ó tá aqui menor do que 2,5 kg e aí eu utilizo ã a função mutate para criar algumas variáveis primeiro esse conjunto de dados aqui ele não tem
(19:54) um uma uma coluna que me represente um um indicador um indicador único de cada uma das linhas e por que que eu fiz isso porque quando eu quero identificar alum olhar para uma observação ou quando a gente tiver olhando lá pros resíduos distância de cook é mais fácil a gente conseguir localizar a observação pelo índice dela então eu coloquei aqui o ID nada mais é do que uma sequência que vai do número um até o número de linhas do nosso conjunto de dados que é 189 ã eu criei a variável L Cat que é o que é uma só tá eu tô informando para o
(20:33) software que a variável baixo peso ao nascer ela é um fator também tô transformando o peso da mãe que tá em libras para quilogramas e da mesma forma como eu fiz com baixo peso eu tô informando pro software que a variável fumon ela também é categórica então se a gente fizesse aqui o STR né para olhar a estrutura dos nossos dados antes de fazer essas transformações a gente ia ver que Smoke ele tá considerando como uma variável inteira da mesma forma que a nossa variável resposta que tá aqui em cima ele também tá considerando como
(21:16) inteiro então executando essas transformações e pedindo para ver a estrutura desse conjunto de dados alterado a gente já entende já verifica aqui que ele entendeu agora que a variável eh baixo peso ela ela é um fator com dois níveis zero e um ã que o peso da mãe é numérica e tá em quilos agora antes estava em libras e que a variável fumo ela também é um fator que tem os níveis zero e um E aí nosso primeiro passo de sempre é contextualizar é explorar conhecer um pouco desses dados nos apropriarmos deles ã então quando a gente executa a função
(22:07) summary aqui dos dados que que a gente já consegue ver a gente sabe que a idade média né aqui das mães é de cerca de 23 anos a gente também tá vendo que H pouco mais de 1/3 das Mães né TM baixo eh dos das crianças dos bebês nasceram com baixo peso ã que o peso médio das mães é de 50 mediano aqui tem uma discrepância né a gente tem uma uma diferença bastante grande entre o peso mínimo e o peso máximo das Mães o peso mediano é de 55 kg a gente tem um peso máximo acima de 100 kg se a gente usar esse essa função vi dados aqui e denar pelo peso da mãe
(23:01) de maneira decrescente a gente consegue ver aqui que quatro mães tinham eh um peso maior do que 100 kg ã aqui é variável de identificação Então como a gente tinha criado ela vai de 1 até 189 o objetivo dela é simplesmente facilitar a gente encontrar uma observação e dentre as mães a gente tá vendo que uma minoria aqui 74 de 189 que dá cerca de 39% das Mães desse conjunto de dados elas fumaram durante a gestação qual é o passo seguinte então esse primeiro passo e o segundo passo eles são comuns a qualquer modelo que a
(23:58) gente faça aí a gente só adapta o contexto que a gente vai est trabalhando Então nesse caso o que que a gente vai fazer como segunda etapa a gente vai avaliar ã as variáveis preditoras os nossos x com o nosso Y variável preditora e a variável resposta que que a gente quer entender aqui o nosso objetivo é conseguir nesse caso a gente tá focado em modelar três covariáveis mas num contexto prático num dia a dia de trabalho numa rotina de trabalho por exemp exemp a gente não sabe quem são os X a gente que tem que definir Quais são
(24:33) os que nesse contexto por exemplo eles Quais são as características que variam que mudam que T algum Impacto que distinguem os grupos entre quem teve baixo peso e não teve Quais são as características da mãe que estão associadas a isso então a estatística descritiva vai ser vai ter esse olhar esse objetivo nesse momento então para pras variáveis que são quantitativas a gente pode olhar de forma descritiva para isso usando o boxplot se a gente fizer um box plot da idade pelas categorias de baixo peso a nascer por
(25:14) exemplo que que a gente percebe a ele tá me trollando hoje nas últimas duas aulas né Pera aí gente aqui a gente vê que o a idade mediana das mães que tiveram filhos com baixo peso ela é inferior à idade mediana das mães que tiveram filhos que não têm baixo peso se a gente quisesse eh testar a hipótese de que as mães que têm a idade mediana ou média das mães que têm filhos com baixo peso é igual à Idade Média ou mediana das mães que não têm filhos com baixo peso O que que a gente poderia usar hipótese teste de hipóteses Qual
(26:14) qual é o teste que se encaixa ou que poderia responder essa pergunta aqui o Putz Fiz trabalho hoje pô que quadrado Que quadrado é de associação esse aqui a gente quer comparar médias então a gente poderia olhar o teste que tem a hipótese nula mi1 média do grupo um igual a média do grupo do é o teste t teste t tem como pressuposto que os dados tenham uma distribuição normal Se eles forem normais excelente é o test que a gente aplica se eles não forem a gente usa o caminho não paramétrico o equivalente não paramétrico que nesse caso aqui
(27:01) alguém lembra teste de Will coxon então a gente poderia complementar essa nossa avaliação aqui com os testes de hipótese então olhamos primeiro pra idade coloquei aqui também pra gente lembrar como é que a gente conseguiria ter acesso a esses valores apresentados no boxplot basta a gente colocar um dólar stats aqui no final do comando e a gente vai ter as informações para cada um dos grupos então baixo peso zero baixo peso 1 ã o valor mínimo Q1 Q2 Q3 e valor máximo próxima variável que a gente tem interesse em comparar em aliás em
(27:53) avaliar ã é sim alguém na tua mão pode falar Gabriela você pode explicar novamente essa parte do status eu não entendi ah tá quando a gente faz o boxplot a gente só só consegue ver o gráfico né a gente não sabe quais são os valores que estão aqui Quais são os valores da mediana não sabemos qual é o valor aqui o mínimo Q1 quando a gente executa esse mesmo comando mas coloca um dólar stats aqui no final ele nos mostra quais são esses valores então a gente tá vendo que o valor mínimo nos dois grupos é o mesmo é
(28:33) 14 ã o valor Q1 25% das Mães tinham até 19 anos num grupo e num outro grupo 19,5 23 é a idade mediana das mães que não tiveram filhos com baixo peso e 22 é a idade mediana das mães que tiveram filho com baixo peso é isso é as estatísticas descritivas que ele apresenta aqui no gráfico Ah legal obrigada de nada então olhamos primeiro pra relação entre baixo peso e idade da mãe próxima variável que a gente tem interesse é olhar pro peso da mãe Ah eu coloquei aqui também uma outra forma de gente obter esses valores né eu
(29:23) fui colocando para que vocês tivessem distintas maneiras de ver que conseguimos fazer ter a mesma informação por diferentes formas se a gente Oi pode falar eu não sei se a professora já comentou min outra aula eh quando você puxou esse dataset eh você já trouxe as variáveis de interesse como é que você selecionou essas variáveis de interesse sim aqui eu tô definindo que nesse contexto faz sentido a gente avaliar essas três Então é pelo enunciado pela ideia do exercício da aula de hoje mas por quê Por que que você definiu essa eu
(30:01) entendi mas pra gente testar pra gente testar aplicar os aplicar o nosso a ideia e os passos do modelo aqui na prática ã a gente não vai saber isso Ah tá tá se eu pegar um dataset com 40 colunas como é que eu faço então fazendo essa etapa que a gente tá fazendo aqui ah e fica tem que F fazendo isso de todos ou você faz uma olha previamente aquele conjunto de coluna fala Não isso aqui não tem muito a ver não com o que eu quero e já vai descartando a gente sempre tem um entendimento prévio e hipóteses quando a gente tá analisando
(30:39) uma tá interessado em um modelo a gente sempre tem hipóteses do que tá ou não relacionado e o que que a gente vai testar se aquilo que a gente imagina que esteja relacionado a gente parte de um pressuposto teórico a gente tem uma Ah eu quero avaliar se h a caracter o tempo daquele cliente o tempo que ele comprou o primeiro plano se tá associado a ele ser chne ou não ser um ch involuntário ou involuntário Então eu tenho hipóteses de negócio que vão guiar esses meus testes e na na prática é nosso papel conseguir identificar quem
(31:18) são esse conjunto de X o que que nos ajuda nisso Essa é primeira avaliação aqui avaliação de cada uma das preditoras com avaliável resposta Bel já obrigado de nada e aí o que que vai ir nos ajudando também nos testes de hipótese a gente consegue identificar que era o que a gente tava falando se a gente tem qual é o teste de hipótese que vai nos dizer se a idade eh Pode ser sim representar uma característica que impacta ã na chance de baixo peso ao nascer a gente pode ir olhando de maneira a testar essas hipóteses cada uma delas
(31:57) para chegar no nosso conjunto Inicial lá de x que a gente vai colocar no nosso modelo mais alguém levantou a mão eh eu professor Rafael Oi Rafael complementando aí a pergunta do do colega Fabrício né imagine lá que tem lá um dataset com com 40 colunas né 40 39 variáveis x e a e o que a gente tem que ter tem que achegar né que é Y né não consigo usar um eh correlação entre entre as as variáveis para poder pelo menos fazer uma seleção prévia aqui a gente tá num a gente tá num contexto que correlação não se encaixa mais por quê Porque a nossa
(32:43) variável resposta ela é sim ou não ela é categórica então o que que a gente pode olhar associações tudo que a gente puder olhar de maneira descritiva que nos ajude a selecionar a gente vai usar a gente vai tentar identificar o o que que faz os grupos serem diferentes Essa é a ideia aqui e quanto mais a gente se munir de informações aqui de forma descritiva mais fácil para ser a gente entendesse o que a gente tá encontrando como resposta como resultado lá na nossa etapa de modelagem faz sentido então a gente começou avaliando
(33:23) idade e olhando um pouco para essas diferenças então parece que sim que a as mães que têm filho com baixo peso Elas têm uma idade mediana inferior as mães da que que não têm filhos com baixo peso agora vamos dar uma olhadinha para peso da mãe e aí a gente vai fazer essas mesmas explorações aqui parece que essa diferença Ela É menor né as mães o baixo peso ã se a gente olhar aqui as estatísticas descritivas a gente tá dizendo que as mães o peso mediano das mães que não t filho com baixo peso é eh superior ao peso das mães que têm filhos com baixo
(34:05) peso mais ou menos 2 kg de diferença entre um e outro que que a gente poderia fazer um teste para ver se essa diferença ela é estatisticamente significativa a mesma ideia do teste aqui de cima se for significativo Opa é um sinal que sim pode ser que essa seja uma variável importante para eu distingui os grupos de de características de mãe que impactam no baixo peso a nascer que é o que eu quero o tô interessada em modelar agora a gente vai olhar por último para relação entre duas variáveis que são ã qualitativas baixo peso e fumo e aí aqui
(34:44) entra a uma análise complementar que poderia fazer com teste que o colega falou poderia olhar se existe Associação de baixo peso e hábito de fumar se eu ol isso de forma descritiva né qualitativa H que que eu consigo ver já aqui pela minha tabela H que compara eu tô comparando aqui ó soma tá eu tô somando 100 dentro de cada grupo e baixo peso então eu tô dizendo que 33% das das mulheres que tiveram filho com baixo peso fumaram versus 51% das mães que não tiveram eh perdão eu eu eu troquei aqui é não certo zero é não então 34% das
(35:35) mães que não tiveram filhos com baixo peso fumaram versus 51% das mães que tiveram filhos com baixo peso fumaram então eu tenho uma proporção de de crianças com baixo de crianças com baixo peso muito maior entre as mulheres que fumaram do que as que não fumaram o que também faz sentido eu pensar que isso impacta de maneira significativa a chance de uma criança nascer com baixo peso professora por favor e eu eu me perdi ali low Cat no caso teve baixo peso então não teve baixo peso e não fumou 6% 66% das mães que não tiveram filhos com
(36:35) baixo peso não fumaram e 34% das mães que não tiveram filhos com baixo peso fumaram durante a gestação tá entendi a forma que você tá analisando eu tô olhando dentro de cada grupo de baixo peso e aí mee que por essa diferença de proporção parece que faz sentido eu pensar que o hábito de fumar impacta na na no fato de ter baixo peso ao nascer e aí se eu fosse fazer algum teste de hipótese Eu poderia usar o teste de associação para ver se existe relação entre fumo e baixo peso certa essa primeira etapa pessoal Então os próximos passos que a gente vai
(37:34) falar agora São ã baseados no no que Na abordagem proposta por rosm e Lemes então eles dão uma série de passos que nos ajudam a escolher quem são os as covariáveis que ficam ou saem do modelo como é que é essa forma né essa proposta de modelagem deles passo número um a gente faz um modelo univariada uma das C variáveis que a gente ã escolheu ou viu que tem que impactam na nossa variável resposta no nosso caso a gente tá olhando para três Então a gente vai gerar três modelos um pra idade um para peso da mãe e um paraa
(38:22) variável que olha característica de fumo né o hábito de fumar da mãe Então a gente vai começar ã só olhando um pouco aqui pro primeiro modelo e vendo o que que ele nos apresenta o que que Ele nos informa quando a gente faz o summary daquele modelo né o olha pro resumo daquele modelo a gente vai falar sobre os as interpretações no final mas só vou falar contemplar um pouco que que ele tá nos informando Quais são as medidas que ele nos dá quando a gente a gente eh usa o modelo glm aqui nesse caso como é que lá
(39:02) a gente no modelo de regressão linear múltipla a gente usava a função LM aqui a gente usa a função glm ã a gente informa variável resposta e ecov variável exatamente como a gente fazia lá a gente precisa informar ele que a nossa distribuição da variável resposta é binomial é uma variável quando a gente se a gente voltar aos slides lá da das aulas que a gente fala sobre isso a gente tem lá que sempre que a gente tá olhando um sim ou não a gente tá falando de uma variável que tem uma distribuição binomial e informa para ele
(39:36) também o conjunto de dados ã que a gente tá avaliando que que Ele nos informa aqui nos dá medidas descritivas de um dos dois tipos de resíduos que esse modelo comporta então ele tá nos mostrando estatísticas descritivas do resíduo deviance nos informa também apresenta os coeficientes do modelo da mesma forma que lá na regressão linear múltipla o que que ele mostra o valor da estimativa então o Beta 0 aqui nesse caso e o Beta 1 ele nos mostra o valor do erro padrão o valor do erro padrão aqui nos ajuda a qu lá no cálculo dos intervalos e
(40:15) confiança nos mostra um valor de uma estatística de teste que que tá sendo testado aqui se esse coeficiente é igual a zero ou não essa hipótese nula Beta 0 igual iG z0 Beta 1 = 0 e nos mostra o valor P dessa estatística de teste Então essa essa parte aqui é exatamente análoga ao que a gente tinha lá no modelo de regressão linear múltipla depois ele nos mostra uma outra uma outra parte aqui com uma informação que é parecida ou familiar com o que a gente tinha lá na última linha do modelo de regressão linear múlti
(40:58) lá ele tinha nos apresentava uma estatística F do modelo aqui ele nos mostra o número de qual é os desvios né a deviance do modelo nulo ou seja um modelo que não tem nenhuma covariável e nos mostra esse resíduo para modelo que tem a covariável aid que é o que a gente tá considerando aqui no M1 e qual que é a ideia aqui quanto melhor o modelo quanto mais mais aquela variável ela explica aquela é variável resposta menor vai ser a diferença entre o modelo nulo e o modelo aqui residual devance então quanto mais poder
(41:41) explicativo essa cor variável tem maior a redução entre o modelo nulo e o modelo que considera que contempla aquela covariável e também por fim ele nos dá uma uma critério de informação de akí que é uma medida que a gente usa e a gente a gente falou lá na aula passada quando a gente quer comparar modelos com diferentes números e covariáveis que que a gente olha aqui quanto menor o valor de A e C quando a gente tá comparando modelos diferentes melhor então sabemos que pro modelo com idade o AIC é 235 ele não tem uma
(42:18) interpretação direta tá pessoal e a última coisa que ele nos fala é que o modelo convergiu porque é um processo interativo é um método né um processo interativo convergiu depois de quatro interações Então é isso que ele tá nos mostrando aos pouquinhos a gente vai falando aqui sobre as outras essas como é que a gente interpreta etc a gente só vai primeiro fazer todo o raciocínio da abordagem ali proposta pelos autores então primeiro fizemos o ajuste considerando a covariável idade depois fizemos o ajuste considerando lá a nossa
(42:56) segunda deixa só eu vou anotar aqui o valor do P PR cor variável que a gente tá considerando Vocês já vão entender por porque a gente vai precisar dessa informação passo dois então o valor p da idade aqui é 0,105 agora Olhando pra segunda covariável peso da mãe valor P dessa cor variável 0,02 por fim olhando pra variável que ind variável indicador indicadora de fumo na gestação valor P desta 0,02 também então fizemos um primeiro passo da Etapa proposta por este autores na abordagem de regressão
(43:59) logística segundo passo que que seria ajustar o modelo multivariável Ou seja que eu tenho mais do que 1 x considerando todas as variáveis que tiveram um p menor que 0,25 aqui no Passo anterior então Quais foram as covariáveis que tiveram um p menor que 0,25 todas elas Então vamos criar um primeiro modelo que vai contemplar Eid peso da mãe e variável indicadora de fumo e aí o summary do modelo já nos indica também o valor P de cada uma delas Qual é o próximo o próximo passo proposto pelos autores e que sempre que
(44:49) a gente usa um método automático de seleção de variáveis é isso que é feito se deixa no modelo apenas as covariáveis que são significativas E aí eu coloquei em letras maiúsculas pra gente sempre lembrar dessa discussão faz sentido essa exclusão dentro do contexto que eu tô trabalhando a gente vai assumir que ok aqui mas a gente sempre precisa ter isso em mente então aqui selecionar todas as variáveis que são né que que são menores que 0,05 significa excluir a idade do ajuste do modelo E aí se a gente volta um
(45:30) pouquinho lá paraas nossas estatísticas descritivas e olha pra idade a gente tá dizendo que essa diferença de 22 para 23 anos ela não não impacta o risco né Não não tá não tá não é algo que impacte ã o baixo peso ao nascer das crianças é isso que a gente tá dizendo quando a gente tá ex indo aquela covariável ali Opa foi para baixo demais certo então chegamos do modelo de Passo três que é o que faz sentido com o que esses autores propõe é só essa abordagem que existe para seleção de variáveis não Quais são as outras as que
(46:19) a gente falou lá na aula passada então o backward stepwise é o stepwise backward e forward Então são métodos automáticos que que eles fazem por exemplo esses dois incluem todas as variáveis um deles tá incluindo uma a uma mantém apenas aquelas questão significativas o outro coloca todas as variáveis no início vai tirando Deixa apenas as que são significativas E aí sempre a mesma fala né a gente tem que pensar se a exclusão daquela covariável faz sentido no contexto que a gente tá trabalhando Então a gente chegou num
(46:56) modelo do Passo três aqui que eu chamei M passo 3 que é o que tá de acordo com as etapas que os autores propõem qual seria o nosso próximo passo verificar as estatísticas e diagnóstico do modelo esse modelo tá bem ajustado ele é um modelo confiável eu posso confiar nas interpretações que eu vou obter a partir dele e aí vamos olhar para aquelas medidas que a gente viu lá nos slides então primeira coisa que a gente vai fazer é o olhar pro teste de Rosemary lem show né uma medida de ajuste Global ã quando a gente executa Então essa
(47:37) função a gente que que é o argumento dessa função é o modelo que a gente quer testar no nosso caso modelo do Passo TRS Opa aqui agora sim e aí só voltando o nosso último modelo então tem apenas n covariáveis que são significativas a 5% de significância né todos os PS aqui os dois PS dos dois betas de cada um das variáveis das covariáveis que a gente tá considerando são significativos E aí quando a gente falou sobre o teste de de rosmy lem lá nos slides eu falei que o que que ele fazia Calculava uma probabilidade para cada
(48:25) uma das observações ele ele ordena essas observações conforme a probabilidade da menor para maior divide ali os grupos em 10 eh divide as observações em 10 grupos E aí ele compara o valor observado com o valor esperado que é o que ele prediz né O que o modelo prediz com base nisso ele calcula uma estatística de teste que nesse caso aqui teve valor de 10 então é valor da estatística de test é uma conta que ele faz com base nessas observações nessa forma aqui que ele eh escreveu o teste de hipóteses dele essa estatística de
(49:05) teste tem uma distribuição q quadrado uma um dos argumentos uns dos parâmetros da distribuição de q quadrado é o número de graus de liberdade então por isso que ele apresenta essas duas informações a partir destas duas informações se chega no valor P esse valor p é o que vai nos ajudar a decidir se a gente aceita ou rejeita a hipótese nula que a gente tá testando aqui nesse caso Qual é a hipótese nula que o modelo tá bem ajustado Então essa é uma das situações que a gente não gostaria de rejeitar a hipótese nula né a gente quer aceitá-la
(49:43) e ã considerando né 5% a gente pode dizer que sim que pelo critério aqui de rosmer e lem show esse modelo está bem ajustado certo até aqui pessoal Ah obrigada Paula Então vamos seguindo primeira coisa que a gente olhou modelo está bem ajustado depois se a gente olha lá nos slides outra coisa outra ã observação Outro ponto importante para avaliar o ajuste do modelo é verificar a distância de cook então coloquei aqui a fora como a gente calcula e coloquei um gráfico para facilitar a nossa exploração sobre sobre a distância de cook que que avalia a
(50:43) distância de cook avalia se tem alguma medida influente né alguma observação influente que que é uma observação influente é aquela que Impacta tá na estimativa doss betas Então se a gente calcula a distância de cook e depois faz o gráfico e aqui essa linha pontilhada ela tá pontilhada no valor que é ã utilizado como uma regra de bolso para ponto de corte a partir de onde um uma observação pode ser considerada uma um ponto de alavanca né uma observação influente Então qual é a regra de bolso é 4 dividido por n sendo que n é o número de
(51:32) linhas daquele conjunto de dados que eu tô avaliando nesse caso aqui a gente tem quatro observações que estão bem acima do nosso ponto de corte vamos dar uma olhada para elas Então se a gente clicar aqui em distância de cook aqui nesse objeto o que que ele vai nos mostrar qual é a distância calculada para cada uma das nossas observações então o que que eu vou fazer eu vou ordenar ã de forma decrescente da maior para menor que que eu tô vendo tô vendo que a observação que tem a maior distância de cook aqui é a de número
(52:18) 147 que que eu vou fazer vou olhar aqui o meu conjunto de dados E aí eu tinha criado uma variável indicador então o que que eu vou fazer vou ordenar essa variável indicadora também para olhar a observação 147 ou também posso vir aqui deixa eu ver se ele me deixa não ele não me deixa às vezes eu consigo vir aqui e selecionar Então tudo bem tirar esse filtro e vou olhar pra observação de número 147 E aí eu tô vendo o quê que é uma observação referente a uma mãe que tem um peso Opa lá tá aqui ela é uma mãe que teve um filho com baixo peso
(53:03) ã e ela tem um peso maior né do que a mediana daquele grupo se eu ordenar esses os meu conjunto de dados de pelo peso de forma decrescente eu vou localizar quatro mã que tem pesos bem altos né todas essas Mães com mais de 100 kg não tiveram bebês com baixo peso Todas estão com não a observação 147 ela tem um comportamento um pouco diferente se trata de uma mãe que tem um peso alto e uma criança com baixo peso é o mesmo caso da observação de número 183 também é o mesmo caso da mãe de número 171 e é o mesmo caso da mãe de
(54:07) número 133 que são as minhas quatro maiores são os quatros maiores valores de distância de cook que eu tenho ou seja são mães que TM uma característica diferente do comportamento esperado de todas as outras Elas tiveram filhos com baixo peso entretanto o peso delas é alto então que que isso pode ser um ício de algum erro de digitação né de algum registro errado ou uma característica específica que fez essas mães terem por alguma razão um peso maior e a informação não não corresponde a um erro quando a gente identifica coisas desse
(54:59) tipo qual é o procedimento que a gente deve tomar independente do modelo de regressão que a gente tá avaliando ou da técnica [Música] enfim exclui os dados esses dados é uma possibilidade Mas antes a gente precisa entender se faz sentido aquela exclusão ou não excluir os dados vai garantir o quê que a gente vai ter betas né que não vão estar influenciados por aqueles comportamentos atípicos mas faz sentido então prévio as a exclusão a eliminação desses dados a gente sempre tem que pensar se faz sentido dado aquele contexto e eu tenho
(55:48) sido bem repetitiva talvez chata nesse ponto mas é pra gente sempre pensar nisso não o fazer pelo fazer mas o fazer pensando no contexto que a gente tá estudando avaliando modelando faz sentido aquela explusão naquele contexto então uma das alternativas seria essa que o Rafael falou seria eliminar essas linhas e repetir o ajuste do modelo né remodelar a gente vai seguir a nível de prática de exercício mas sim tirar essa as observações pelo que indica que o gráfico da distância de cook seria o mais adequado por este única e
(56:35) exclusivamente por este critério próximo passo avaliação dos resíduos Então a gente tem dois resíduos que a gente vai olhar com o objetivo de tentar identificar se existe algum padrão Ou não os resíduos de pearson e os resíduos da deviance como é que a gente calcula aí aqui usando a função residuals a gente sempre passa Qual é o modelo que a gente tá ajustando E qual é o tipo de resíduo que a gente quer calcular se é o resíduo de peon ou se é o resíduo da devance E aí usa o comando plot para conseguir gerar os gráficos desses
(57:19) resíduos Esse comando é blind só vai colocar aqui setar uma linha no zero paraa gente ter uma referência que que a gente observa aqui que a gente tem dois padrões distintos né Tem um aqui que tá mais para baixo um que tá mais para cima será que isso é um problema e ou por que que isso tá acontecendo se a gente for olhar a forma como esse conjunto de dados ela tá estruturada a gente percebe que primeiro tão ã estão informad todos as todas as características das mães que não tiveram filhos com baixo peso então eu tenho
(58:04) várias linhas de zeros e depois eu começo com as linhas de uns é por isso que a gente tem essa diferença aqui a gente tem um grupinho que teve zero aqui que não teve baixo pesão na C e o grupinho que teve um única e exclusivamente por conta da forma como esses dados Estão dispostos no conjunto de dados se a gente utilizar aqui quando a gente for informar eh qual é o valor do eixo X a função sample a gente dá uma misturada nessas linhas e aí a gente perde esse padrão aqui que pro nosso objetivo Está ok perder isso a gente só quer verificar
(58:43) se existe algum padrão no comportamento dessas eh do resíduo né da distribuição dos resíduos desses grupos como a gente tá sempre aqui num contexto de regressão logística a gente sempre vai ter né a gente tá olhando para um para uma resposta que é zero ou um a gente sempre vai ter esses resíduos distribuídos em dois grupos então aqui nesse caso isso não representa um padrão Ou algo que é um ponto de atenção Ele sempre vai ser assim pela característica deste modelo e o que que a gente vai buscar olhar se dentro de cada um desses grupos
(59:18) a gente tem alguma observação que se destaca e aqui já tem uma que a gente vê que tá um pouquinho mais para cima né ela tá um pouquinho mais distante de que do que todas as demais da mesma forma se a gente vier aqui e olhar os esse objeto que onde a gente armazenou os resíduos de pearson e ordenar ele de maneira decrescente a gente vai ver que vai tá falando lá da observação de número 147 que também era aquela que tinha a maior distância de cook então mais uma evidência aqui talvez sim eliminar essa essas essas
(59:57) observações vão tá ajudando na qualidade de ajuste do nosso modelo a mesma observação né a mesma avaliação agora a gente vai fazer pros resíduos do tipo deviance então é a mesma ideia os valores vão ser um pouco diferentes porque são métodos de calcular distintos e a nossa ideia o nosso foco vai ser o mesmo aliás se a gente tem padrões distintos E aí da mesma forma que lá pros resíduos de pirson tem uma observação aqui que se destaca que Opa abriu o mesmo objeto aqui resíduos deviance que se a gente hã ordena de
(1:00:44) forma decrescente também se refere aquela observação de número 147 então olhando até essa etapa a gente cumpre né O que que a gente teria que fazer para ter certeza que estamos sendo né estamos tendo o melhor ajuste possível a gente deveria eliminar as quatro observações que a gente detectou lá no método lá da distância de cook pelo método da distância de cook por quê Porque são observações que puxam elas influenciam nas estimativas dos betas a gente poderia também fazer aquele mesmo exercício que a gente fez ali na aula
(1:01:29) passada que era ter o modelo com todas as observações ter um sem aquelas e comparar Qual é o impacto da exclusão dessas linhas na estimativa dos parâmetros tá aqui de novo para fins da gente fazer o exercício e olhando os passos eu vou seguir sem excluir as variáveis entendido pessoal até aqui Então vou eh supor que o modelo aqui três o modelo do Passo três é o que a gente vai considerar como covariável e agora que o que a gente vai olhar é ã como é que a gente interpreta esses parâmetros Então como a gente tinha visto lá no nos
(1:02:28) slides da aula o que a gente interpreta aqui no modelo de regressão logística não são os betas mas sim a exponencial desses betas e eles nos indicam um ods eles nos indicam uma chance quando a gente faz então a exponencial desses coeficientes que que eles representam então primeiro a gente sempre vai tá o olhando se ele tá se é um valor maior do que um ou menor do que um quando esse valor for menor do que um ele indica uma redução na chance do evento que a gente tá modelando acontecer e uma redução de quanto de um menos esse
(1:03:19) valor então aqui paraa questão do do peso da mãe no quilo que que isso significa que para cada aumento de 1 kg no peso da mãe a chance do bebê nascer com baixo peso reduz em 3% porque é 1 - 0,97 quando a gente olha paraa variável de fumo por outro lado a gente tem um valor que é maior do que um Então como é que a gente interpreta isso E aí aqui a gente tá falando de uma variável que ela é categórica o valor que a gente tá observando Ele tá nos dizendo aqui a gente vai tá interpretando o um ou seja as mães que
(1:04:04) fumaram em relação a categoria que não aparece aqui categoria de referência no nosso caso aqui é a zero Então significa que as mulheres que fumaram na gestação Elas têm 1,97 vezes a chance ou 97% uma chance 97% maior de ter um filho com baixo peso do que as mães que não fumam então a gente olha aqui ã no caso de uma variável quantitativa da mesma forma que a gente olha lá na na regressão linear né a gente olha pro aumento de uma unidade Mas e se o nosso interesse não fosse saber no aumento de 1 kg mas sim no aumento de 10 Kg Então o
(1:04:53) que a gente ia fazer simplesmente era multiplicar por esse aumento x que é o que a gente tem interesse em saber maior do que um multiplicar o valor pelo coeficiente de interesse e fazer exponencial dele nesse caso para cada aumento de 10 Kg no peso da mãe a gente reduziria em 25% a chance da criança nascer um baixo peso e aí sempre que a gente apresenta ess estimativas pontuais também é interessante que a gente mostre o intervalo de confiança dela ah uma outra coisa que eu não falei e que tá escrito lá nos slides quando o valor
(1:05:39) ã de Beta aqui ele é menor do que um ind indica um fator de proteção então peso da mãe é um fator de proteção reduz o risco da criança nascer com baixo peso Em contrapartida eh fumar o hábito de fumar da mãe aumenta o risco então é um fator de risco para baixo peso ao nascer ã voltando ao que eu tinha começado então apresentamos estimativas pontuais e sempre é importante a gente apresentar também o intervalo de confiança nesse caso como é que a gente obtém o intervalo de confiança é utilizando a função conf in o Def o nível de
(1:06:27) confiança Def é 95% dá pra gente mudar caso a gente queira algum outro intervalo só alterando a a meu Deus me fugiu a palavra alterando aquela parâmetro aquele parâmetro obrigada Marcelo o parâmetro dessa função confiente e aí fazendo exponencial a gente consegue obter para cada um dos nossos Inter dos nossos vari explicativas Qual é o intervalo de confiança Falei rápido né então respondendo aqui ao nosso objetivo que era avaliar quais eram os fatores que estavam relacionados ao baixo peso ao nascer peso da mãe de uma
(1:07:19) maneira que protege mães que TM um peso maior tão um fator de proteção para baixo peso da Criança e fumo é um fator de risco mães que fumaram na gestação tem uma chance maior de ter um filho com baixo peso do que mães que não fumaram e maior quanto a gente pode olhar a estimativa pontual é 97% maior e esse 97% tá entre 4 e 273 por.
(1:07:50) é um intervalo de confiança bastante grande a gente tem um tamanho de amostra aqui que é só 189 crianças se a gente tivesse uma amostra maior provavelmente esse intervalo de confiança aqui teria uma amplitude menor Então essa a ideia da regressão logística pessoal contexto onde a gente tem um Y que é zero ou um aqui nesse caso Desse exemplo que a gente tá vendo a gente focou numa variável numa regressão logística binária existe só regressão logística binária não existem as Segre sões logísticas para mais do que uma var mais do que uma mais do que duas
(1:08:30) categorias né de resposta são as as regressões politômicas ordinais ou nominais existem outras né dependente do contexto classes específicas de modelos para isso certo sobre essa primeira etapa pessoal nenhuma dúvida nenhuma dúvida é muito forte né achei mais pesada do que a linear mas ok sim a ideia é um pouquinho diferente né Ela é um pouquinho mais tem uns detalhes um [Música] pouquinho professora só ten uma pergunta ali por exemplo na hora de fazer o trabalho se a gente encontrar uma variável ali que poderia ser excluída
(1:09:25) pelas análises a gente vai ter que excluir e continuar a análise justifiquem o raciocínio de vocês uhum não existe um certo um errado existe um motivo para excluir da né que é o motivo que o O que que a gente sabe naquelas naquelas variáveis ali por exemplo ponto de alavanca ele vai ter um impacto na estimativa do Beta mas no meu contexto vamos supor que não faz sentido nenhum eu excluir que faz aquela observação é aquilo mesmo e eu quero de fato eu tenho casos de mães que TM um peso maior e t filhos com baixo peso e eu quero que o meu modelo
(1:10:01) leve isso em conta eu tenho uma justificativa teórica para para ter um argumento teórico que me fa considerar aquilo na na minha amostra então eu mantenho mas eu justifico Ok é só vai justificando os passos e se todos nós fôssemos modelar a mesma situação a chance da gente cada um de nós chegar num modelo diferente dados né o seu contexto o seu conhecimento sobre aquele assunto isso sempre existe pode falar Leandra ô professora eu na verdade meu microfone aqui ele parou e aí eu tive que reiniciar o meu computador quando eu cheguei na parte
(1:10:46) ali do do g do boxplot logo ele o meu ele tá dando um erro deixa eu ver se aqui vai e qual erro tem o passo um dois Deixa eu só chegar aqui nele que eu tive que reiniciar tudo de novo deixa eu eu posso compartilhar aqui sim deixa eu parar aqui meu que aí depois eu eu continuo aqui ele tá dando erro per Deixa eu só aumentar aqui para conseguir enxergar aqui eu consegui né distância de Ah não foi impossível encontrar a a
(1:11:53) função GG plot tá precisa rodar ex aquele require plot 2 eu eu eu confesso que eu já fiz isso sabe vamos ver ah é porque sempre que ele dá esse erro é porque ele não conseguiu achar a função porque o pacote não tá carregado tá joia obrigada tá vamos de nada pode falar Gabriela lá professora eu não peguei só uma parte eh eu não assim quando quando que a gente vai saber eh quando utilizar a regressão linear ou a regressão logística Existe algum tipo de dado que vai melhor com uma do que com a outra ess entendi o que que muda de uma
(1:12:50) para outra é justamente a nossa variável resposta é o que que a gente tá modelando quando a gente tá falando de uma regressão linear múltipla a gente tá num contexto em que o nosso y a nossa variável resposta aquilo que a gente quer modelar é uma variável contínua quantitativa contínua quando a gente tá no contexto de regressão logística a gente tá falando de um dado que é qualitativa uma variável binária uhum essa é é a maior diferença entre eles uma variável binária o quê uma variel quitativa E aí nesse caso a gente tá
(1:13:28) falando da regressão logística binária então a a nossa variável resposta ela tem duas categorias e Ger a gente modela algo que é sim ou não ok tá bom Obrigada nada Pessoal se ninguém mais tiver dúvidas vou começar a falar um pouquinho a ideia é discutir um pouquinho sobre fazer um fechamento assim da do que a gente viu na disciplina de como que isso se encaixa no contexto de de trabalho de ciência de dados podemos começar essa discussão querem encerrar algum querem eh questionar alguma outra coisa da dessa capa de
(1:14:19) modelo professora eu queria tirar uma dúvida eu tava eh procurando uma base de dados né né para eh a princípio para aplicar regressão linear e aí como você acabou de falar tem esse conceito da eh da variável precisar ser contínua certo sim se for Uhum aí eu são são dois cenários específicos um era assim por exemplo Ah eu encontrei uma base que falava de preço de móveis só que o preço de imóveis Ao invés dele ter o valor contínuo ali com a casa de a vírgula né ele pulava por exemplo 2000 2000 e alguma coisa E aí o gráfico
(1:15:02) começava a ficar meio estranho a hora que eu que eu ah o gráfico dos resíduos é quando a gente precisa enxergar a linha né Eh do das inf relação linear é isso não formava uma linha e eu imaginei que era por causa desse salto dos valores pode ser ah mas nesse caso específico dos preços quando a gente fala que Y tem que ser uma variável contínua ela ele assume valor em qualquer intervalo dos reais então o preço mesmo que ali ele não esteja modelado como não esteja escrito como ponto Uhum ele é ele pode assumir não
(1:15:38) não necessariamente naquela amostra ele assumiu isso Hum OK tá bom Beleza o que tu pode fazer é testar eh testar ali todas as etapas e ver se lá naqu quando a gente testa as pressuposições do modelo se aquele gráfico de linearidade a suposição de linearidade Tá aceita é então nessa parte que eu que eu identifiquei que não mas aí eu vou dar uma olhada novamente assim agora ficou mais claro beleza eu tava achando que ainda dentro do meu eh da minha base de dados eu precisava enxergar isso mas não é só o conceito do
(1:16:13) valor que eu estou procurando não necessariamente eu vou ter valores em todos eles né sim tá bom Beleza então esclareceu por completo Obrigada imagina tá então vou fazer assim ó eu vou começar a falar um pouquinho sobre ã um fechamento assim das coisas que a gente que a gente discutiu deixa eu compartilhar a tela senão vocês não vão ver foi né pessoal sim tá B Obrigada Ah então Opa lá deixa eu só fazer diferente senão não vejo aqui então qual que é a a ideia aqui pra gente fechar a disciplina como um todo e ver onde é que
(1:17:18) a gente tá onde é que as técnicas que a gente falou aqui estão no contexto de um projeto de ciência de D então o que que a gente vai fazer a gente vai olhar para fluxo se a gente colocar no Google a etapas de que envolvem projetos em ciência de dados a gente vai ver fluxos diferentes mas todos eles têm algumas etapas em comum escritas de jeitos diferentes muitas vezes então tem alguns que falam de uma especificação de uma pergunta preparação do conjunto de dados processo de limpeza análise compartilhamento dos resultados
(1:17:52) que a gente encontrou e gerar plano de ação a partir deles outros listam a a etapa de coleta limpeza análise exploratória construção de um modelo e disponibilização desse modelo outros ainda vão um pouco mais detalhados então especificação do problema ã obtenção dos dados prepara daí tem a a etapa de modelagem né planejamento do modelo construção do modelo visualização comunicação e disponibilização desse modelo para ser utilizado pela área de negócio outros mostram então começam partindo de um entendimento de negócio
(1:18:37) obtenção de dados preparação dos dados análise exploratória modelagem avaliação e ofertar esse modelo para a produção né torná-lo em um processo em produção e torná-lo disponível para o negócio em então em suma todos eles envolvem um ciclo que parte de uma pergunta né de uma pergunta de negócio do entendimento do negócio e de dados que nos auxiliam e apoiam naquela naquele entendimento e que vão nos ajudar a responder a pergunta que se tem interesse a partir da obtenção e entendimento desses dados a gente faz
(1:19:21) toda uma etapa de preparação para quê para as vezes uma etapa de modelagem feito o modelo a gente precisa avaliar ter certeza que ele tá bem ajustado que ele representa que estimativas seguras que a gente pode confiar nele e disponibilizar esse modelo gerado para a área de negócio dentre as coisas que a gente viu e discutiu aqui em que etapas elas se aplicam dentro desse fluxo né então a gente viu e muniu vocês de técnicas que envolvem e podem são aplicadas nas etapas de entendimento dos dados preparação dos
(1:20:03) dados a gente viu duas técnicas bem básicas sobre modelagem e eh avaliação desses modelos então são todas essas essas caixinhas que a disciplina de estatística básica tinha por objetivo munir vocês de técnicas para auxiliá-los nestes pontos as outras disciplinas vão aumentando o Arsenal né de técnicas disponíveis para você vocês conseguirem passar por pelo fluxo como um todo então se a gente pensa na análise exploratória que que em que partes ela vai nos ajudar ela vai nos ajudar na parte de limpeza né identificação de outliers
(1:20:49) como o colega falou na aula passada a tinha um modelo com um erro de de preço um erro de no preço então aqui são etapas que a gente pega lá no início lá na análise exploratória de dados que por mais que pareça que é uma etapa chata e por mais que pareça que é uma etapa muito manual e por mais que pareça que é uma que eu sou repetitiva quando falo é porque sim é muito importante essa primeira etapa quando a gente constrói um conjunto de dados sólido para etapa de modelagem tudo tudo é mais fácil e faz mais sentido eu costumo falar que a
(1:21:25) qualidade daquilo que sai de um modelo tá muito relacionado à qualidade daquilo que entra daquilo que a gente passa para um modelo então todos os cuidados que a gente tem que ter quando a gente tá preparando a nossa Análise São coisas que a gente viu abordou e contemplou e que a análise exploratória ela é a ferramenta que a gente utiliza em muito nesse contexto nessa nesse sentido avaliação de qualidade dos dados transformação dos dados é simétrico não é simétrico para aquilo que eu vou fazer importa isso ou não Não
(1:22:01) me importa mas eu tenho esse conhecimento Eu já vi isso eu já sei né Eu já eu já entendi como é que se comportam os meus dados como é que eles são eu já sei que eu tô segura em relação a eles Eu já eu já tenho uma ideia do que que eu posso esperar Quando eu fizer um modelo porque a estatística descritiva os testes hipótes mas já me deram uma noção do que que eu posso esperar a parte do dos Testes de de hipótese né eles vão nos entender a vão nos auxiliar a entender as relações entre as variáveis né Por exemplo a
(1:22:32) gente tem lá o teste de associação o teste de quadrado a gente consegue olhar ah testes lá de correlação eles permitem com que a gente teste hipóteses de negócio né E aí quais são os cuidados que a gente precisa ter aqui ouvir conseguir fazer a tradução de uma hipótese de um problema de negócio para uma hipótese estatística conseguir Identificar qual é o teste que responde aquela aquela pergunta e cuidar porque os testes tê pressupostos assim como os modelos que a gente falou até aqui então se eu tô usando um teste eu tenho que
(1:23:08) garantir que ele que eu atendo os pressupostos que ele utiliza ã quando a gente tá falando de modelos a gente viu aqui dois muito básicos a gente tem que ter o cuidado de selecionar a técnica apropriada para o contexto que a gente tá trabalhando Então aqui a gente olhou para dois contextos diferentes se eu tô pensando num num cenário quantitativo de uma resposta quantitativa a gente falou em modelos de regressão linear múltipla se a gente tá num outro contexto que é uma regressão que é um uma variável resposta
(1:23:44) com característica de um de um dado binário né uma uma variável resposta qualitativa a gente tá falando de um modelo de de regressão logística então selecionar a técnica adequada para o contexto que eu quero responder ter o cuidado de sempre dividir o nosso conjunto em treinamento ou teste não fizemos mas são etapas ã etapas defold de todos os métodos sempre que a gente fala de modelagem Por que que a gente não fez porque a gente eu foquei em em falar sobre a técnica e os cuidados que a gente tem que ter porque tudo o resto pessoal eh São
(1:24:21) Passos intermediários que a gente tem que fazer quando faz modelagem não é é isso que ia mudar o entendimento de vocês da técnica ajuste do modelo ter certeza que a gente tá atendendo as suposições que são base que aquele modelo exige né que ele foi construído e pressupõe e avaliação do modelo então a gente fez né Tem chegou lá no modelo colocou ele em produção Acabou o nosso trabalho não a gente tem que monitorar Aquele modelo como é que ele tá se portando em relação aos dados que a gente tá né Aos novos dados que ele tá utilizando para para
(1:25:00) para predizer um comportamento né vamos supor que a gente tá usando lá o modelo para classificar novos clientes a gente consegue medir Qual é o erro que ele tá Qual é acurácia daquele modelo cada não existem formas da gente ir avaliando monitorando as medidas de de qualidade daquele modelo para que quando se ultrapasse um valor lá que a gente estipula Pou a gente tem que pensar em retreinar ou periodicamente retreinar Enfim tudo depende muito do contexto que a gente tá trabalhando mas a etapa ess essas essa etapa né de que envolvem modelos elas
(1:25:39) não são coisas que a gente faz e deu para sempre tá atendido não a gente tem que monitorar cuidar retreinar é um um processo que nunca se finda também tentamos abordar ferramentas que na entrega então aqui a gente falou um pouco e eu pedi para que vocês entregassem todos os todas as atividades em formato HTML que é um formato que a gente pode e particularmente é o que eu utilizo no trabalho a gente consegue otimizar personalizar esse esse esses htmls que a gente gera com logo com a cor enfim deixar um padrão que tem a identidade
(1:26:22) visual da empresa e e é o é algo que o time que eu trabalho utiliza e muito para entregar de forma rápida análises específicas e pontuais que auxiliam eh em para na resolução de problemas menores e quando a gente fala nesses relatórios em HTML tem alguns pacotes gráficos interativos que talvez até tenha comentado ã mas que eu não aprofundei porque não era o objetivo aqui eh mas eu deixei listado alguns pacotes muito bons bem dinâmicos né são bem amigáveis pro usuário que não é da nossa área que é a pessoa com quem a gente tá
(1:27:07) lidando todos os todos os dias são pessoas que não são técnicas então tem várias formas vários gráficos vários layouts distintos que a gente pode otimizar customizar ã e várias opções eu gosto particularmente muito desses pacotes e também a gente tem algumas outras alguns outros pacotes que nos auxiliam a formatação de tabelas então deixar também as tabelas mais bonitas dá pra gente filtrar dá pra gente ordenar dá pra gente exibir quantas linhas a gente quer enfim tem n opções que a gente pode fazer para customizar e para melhorar
(1:27:44) para deixar os nossos relatórios mais bonitos e e facilitar a vida de quem vai utilizar e eu entendo que esse é um dos os nossos maiores desafios da prática com ciência de dados é tornar o nosso trabalho ã o nosso entregável fácil e descomplicado para algum usuário que não é técnico conseguir utilizá-lo entendê-lo com clareza e a partir dele tomar decisões então muito da ideia das nossas aulas foi guiada em fornecer para vocês uma máximo de detalhes práticos que vocês precisam muito mais do que detalhes técnicos detalhes práticos que
(1:28:30) vocês precisam saber ã para ajudar no trabalho de de vocês em análise de dados como um todo usando todas essas técnicas básicas e que agora vocês a partir delas vão conseguir né a ferramenta básica que vocês precisam é o insumo básico que vocês precisam para ir avançando nas próximas disciplinas deixa eu achar um minutinho e esse foi o meu maior objetivo pessoal conseguir transmitir um conhecimento que nem sempre é muito simples da forma mais simples e mais objetiva possível eu espero muito ter conseguido contribuir pra formação de
(1:29:24) você vocês muito mesmo tô à disposição para dúvidas também me coloco à disposição eu vou deixar aqui o meu e-mail particular caso alguém em algum momento Queira discutir alguma coisa específica também né não dula Extra aula enfim tô disponível nesse sentido assim de conseguir ajudá-los certo deixa eu escrever aqui antes que eu esqueça pode falar Paulo eu tenho uma dúvida professora sobre a entrega do trabalho final ali último trabalho né ali são duas entregas uma entrega normal e a outra recuperação que vai usar dois estilos de modelagem
(1:30:12) um que vai pegar digamos a linear ali e a outra entrega da logística a minha dúvida é eu posso usar a mesma base de dados caso esse dataset perm as duas avaliações dois sim pode daí facilita no Ed depois sim pode usar sim só deixa bem claro Qual é o teu objetivo num Qual é o objetivo no outro para eu entender se faz sentido aquilo e pode seguir alguma dúvida mais pessoal Ô profe nãoa só tenho agradecer porque abriu um divisor de águas assim eu acho que é mais é com tempo mesmo que a gente vai colocando em prática né tudo
(1:31:10) que eh você conseguiu passar pra gente eu tô ainda aqui na parte do exercício que ainda deu um erro aqui que é nessa parte do da avaliação TR aí tem lá o plot né E aí embaixo tem o abline Ah sim Aine Aham isso Aine ele não o meu ele ele tá dando erro aqui quando chega Nessa execução eu tenho que abaixar alguma coisa ele dá algum mesmo erro que ele não reconhece a função ou um erro diferente ele dá o acho que é um erro que não reconhece tá se for coloca assim ó vou escrever aqui no chat assim Anes só um pouquinho tentar carregar o pacote o
(1:32:21) pacote que tem essa função esse Graphics uhum tá eu vou tentar vou H vamos encerrar a gravação E aí eu fico aqui disponível pessoal caso alguém tenha alguma dúvida Queira discutir alguma coisa mas eu agradeço
